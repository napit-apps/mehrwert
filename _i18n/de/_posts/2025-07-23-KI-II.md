---
layout: post
title: Green Coding mit KI – ChatGPT als Werkzeug für nachhaltiges Programmieren
cover: cover.jpg
type: "Artikel"
datum:  "23.07.2025"
post_image: "/assets/images/blog/2024-06-07-green-coding.jpg"
tags: "#green-coding, #nachhaltigkeit, #ki"
categories: de posts
author: "Alina"
featured: false
---

Im ersten Teil unserer Artikelserie ([Künstliche Intelligenz - Zwischen Heilsversprechen und Innovationsillusion](https://mehrwert.tech/KI)) haben wir uns mit dem Spannungsfeld zwischen **Künstlicher Intelligenz** und **Nachhaltigkeit** beschäftigt: Wie können wir sicherstellen, dass KI nicht nur ressourcenintensiv arbeitet, sondern auch zur Lösung ökologischer Probleme beiträgt?

Im zweiten Teil unserer Serie wenden wir uns der Praxis zu: Wie lässt sich **ChatGPT im Entwickleralltag** so einsetzen, dass möglichst **nachhaltiger, energieeffizienter Code** entsteht? Dabei werfen wir einen genaueren Blick auf **aktuelle Studien**, analysieren **Stärken und Schwächen** von LLMs – und zeigen, wie sich die Tools bereits heute gezielt auf **Green Coding** trimmen lassen – und wie man dieses **Potenzial direkt im Alltag** nutzbar macht.

Bevor wir konkret auf die Einbindungsmöglichkeiten in ChatGPT eingehen, stellt sich eine grundlegende Frage: **Kann ein Sprachmodell wie ChatGPT überhaupt energieeffizienten Code erzeugen – und wenn ja, unter welchen Bedingungen?** Denn nur wenn dieses Potenzial grundsätzlich vorhanden ist, lohnt es sich, über geeignete Methoden und Kontexte zur Umsetzung nachzudenken. Genau das beleuchten wir im nächsten Abschnitt anhand **aktueller Forschungsergebnisse**.

### Kann ChatGPT überhaupt energieeffizienten Code liefern?

Die Antwort lautet: **Ja – unter bestimmten Voraussetzungen**. Aber nicht automatisch. Eine zentrale Quelle hierfür ist die Studie „Generating Energy‑efficient Code with LLMs“ ([Tom Cappendijk et al., 2024](https://arxiv.org/abs/2411.10599)). In einem kontrollierten Experiment wurden fünf große LLMs (darunter CodeLlama‑70b und DeepSeek‑Coder‑33b) aufgefordert, drei verschiedene LeetCode‑Probleme zu lösen. Die verwendeten Prompts reichten von neutralen Anweisungen („Solve this problem“) bis hin zu gezielten Formulierungen wie „Give me an energy‑optimized solution…“ oder „Use library functions“.

Die Studie kommt zu dem Schluss, dass **Energieeinsparungen durch den Einsatz von LLMs grundsätzlich möglich sind** – allerdings nicht zuverlässig. In manchen Testszenarien führten bestimmte Kombinationen aus Modell, Aufgabenstellung und gezieltem **Prompting** zu signifikanten Verbesserungen in der Energieeffizienz: So konnten durch den Einsatz **effizienter Bibliotheksfunktionen** oder **optimierter Schleifenstrukturen** Einsparungen von bis zu **60 %** erzielt werden. Gleichzeitig zeigte sich, dass es **kein Prompt gab, der in allen Fällen zu effizienterem Code führte**; teilweise erzeugten die Modelle sogar deutlich weniger effizienten Code, insbesondere bei komplexeren Problemstellungen.

Entscheidend ist dabei das sogenannte **Prompting**: Nur wenn im Prompt explizit auf Energieeffizienz oder bestimmte Programmierpraktiken hingewiesen wird, **steigt die Wahrscheinlichkeit**, dass die generierte Lösung auch tatsächlich ressourcenschonend ist. Ohne solche Hinweise bleibt der Output in Bezug auf seine Energieeffizienz **weitgehend unvorhersehbar**.

Die Studie zeigt: LLMs wie ChatGPT können **durchaus energieeffizienten Code generieren** – wenn man sie gezielt dazu anleitet. Entscheidend sind **klare Prompts** und ein sinnvoller **Kontext**. Ohne diese bleibt das Potenzial ungenutzt.

### KI-gestütztes Refactoring: Was die Forschung zeigt

Ein zentrales Problem der bisherigen Ansätze ist, dass sie sich meist auf die reine Bewertung von KI-generiertem Code konzentrieren. Sie geben Hinweise darauf, wie energieeffizient ein bestimmter Output ist – bieten aber keine konkrete Methode, wie sich bestehender Code automatisiert verbessern lässt. Genau hier setzt ein Forschungsteam der Purdue University ([Peng et al., 2024](https://arxiv.org/abs/2410.09241)) einen Schritt weiter: Sie entwickelten einen Prototyp für ein automatisiertes **Refactoring-System**, bei dem **zwei LLMs miteinander kooperieren**, um bestehenden Code systematisch energieeffizienter zu gestalten.

Der Ablauf: Ein erstes Modell (z. B. GPT-4) analysiert den gegebenen Code und schlägt eine **optimierte Variante** vor, die weniger Ressourcen verbrauchen soll. Ein zweites Modell evaluiert diesen Vorschlag – es prüft die **funktionale Korrektheit** und misst (mittels eingebundener Telemetrie und Laufzeitdaten) den tatsächlichen **Energieverbrauch**. Auf Basis dieser Rückmeldung kann das erste Modell **iterativ Verbesserungen** vornehmen.

Das Ergebnis: In rund der Hälfte der Testfälle konnte der **Energieverbrauch signifikant gesenkt** werden – teils auf weniger als die Hälfte des ursprünglichen Werts. Besonders interessant: In mehreren Fällen übertrafen die Refactoring-Vorschläge die Optimierungen, die klassische **Compiler-Techniken** erreicht hätten.

Dieser Ansatz zeigt deutlich das **Potenzial von LLMs im Bereich nachhaltiger Softwarepflege**: Statt nur neuen Code effizient zu generieren, könnten sie auch bestehenden Code automatisch an moderne **Effizienzstandards anpassen** – ein vielversprechender Ausblick für Tools der Zukunft.

### Green Coding Guidelines: Wie man ChatGPT kontextsensitiv trainiert

Wer das Potenzial von LLMs wie ChatGPT konkret für die eigene Praxis nutzbar machen will, kann bereits heute auf verschiedene bewährte Methoden zurückgreifen. Denn auch wenn Studien zeigen, dass LLMs nicht automatisch energieeffizienten Code generieren, lässt sich ihre Qualität durch gezieltes Prompting und gute Kontextführung erheblich verbessern.

Wer möchte, dass ChatGPT bei der Codegenerierung systematisch auf Energieeffizienz achtet, kann das über verschiedene Wege erreichen:

<ul>
<li><b>Persistente Custom Instructions</b><br>
Mit Benutzerdefinierten Anweisungen (in der ChatGPT-App über das Einstellungsmenü erreichbar, nur für ChatGPT Plus/Enterprise) lassen sich dauerhafte Hinweise hinterlegen, die bei jeder Unterhaltung automatisch berücksichtigt werden. <br>
Diese Hinweisungen werden dann kontextübergreifend angewendet – unabhängig davon, in welchem Projekt oder Gespräch man sich gerade befindet.</li>

<li><b>Styleguides oder Markdown-Dateien hochladen</b><br>
GPT-4 unterstützt Datei-Uploads. So kann man eigene Guidelines direkt in den Kontext geben – etwa als `green_coding_guidelines.md` – und explizit darauf hinweisen, dass diese beachtet werden sollen.</li>

<li><b>Eigene GPTs mit Systemprompts bauen</b><br>
Über die "Explore"-Funktion lassen sich spezialisierte GPTs anlegen, die dauerhaft Green-Coding-Ziele verfolgen. Inklusive fester Prompts und optionaler Wissensdateien.</li>

<li><b>Klar formulieren & strukturieren</b><br>
Regeln sollten positiv, eindeutig und in Bulletpoints formuliert sein. Verstärker wie "immer" oder "unbedingt" helfen der KI, Prioritäten zu setzen.</li>
</ul>

**Ein gutes Prompting ist der Schlüssel** – und oft reicht schon ein einzelner Satz, um die Qualität der Code-Vorschläge spürbar zu verbessern. Ein Beispiel, das sich im Alltag bewährt hat, lautet:

> "Handle als erfahrener Softwareentwickler. Prüfe den folgenden Code hinsichtlich Performance, Wartbarkeit und Energieeffizienz. Gib konkrete, umsetzbare Verbesserungsvorschläge zu jedem dieser Aspekte."

Dieser Prompt stammt aus einem Praxisartikel von ([Ash Explained, 2024](https://ashexplained.com/how-to-improve-code-reviews-using-chatgpt/)) und lässt sich leicht anpassen. Wer systematisch effizienteren Code erzeugen oder überprüfen möchte, kann solche Hinweise direkt ins Prompt aufnehmen oder durch persistente Einstellungen dauerhaft verfügbar machen.

### Green Coding Checkliste (zum Einbetten oder Hochladen)

Hier ist eine Liste mit entsprechenden Green Coding Principles. Diese lässt sich – wie oben beschrieben – auf vielfältige Weise bei ChatGPT einbinden: etwa direkt im Prompt, als Systemanweisung in einem Custom GPT oder als Markdown-Datei im Gesprächsverlauf. Natürlich kann die Liste auch weiterentwickelt und an projektspezifische Anforderungen angepasst werden:

<h3> Green Coding Richtlinien für energieeffiziente Software</h3>
<h4> Allgemeine Prinzipien</h4>
<ul>
  <li>Effiziente Algorithmen & Datenstrukturen verwenden</li>
  <li>Redundante Berechnungen vermeiden</li>
  <li>Caching & Memoization einsetzen</li>
  <li>Busy-Waiting vermeiden</li>
  <li>Speicherverbrauch gering halten</li>
  <li>Aufgaben sinnvoll parallelisieren</li>
</ul>
<h4> Python-spezifisch</h4>
<ul>
  <li>Vektorisierte NumPy-Operationen statt Schleifen</li>
  <li>Generatoren statt Listen verwenden</li>
  <li>Dateien zeilenweise einlesen</li>
  <li>Objektinstanziierung in Schleifen vermeiden</li>
</ul>
<h4> Java-spezifisch</h4>
<ul>
  <li>Keine Objekt-Allokationen in Hot-Loops</li>
  <li>Streams statt Komplettladungen</li>
  <li>Primitive Typen bevorzugen</li>
  <li>Konstanten mit <code>final</code> kennzeichnen</li>
</ul>
<h4> Technologieübergreifend</h4>
<ul>
  <li>Schleifenbedingungen auslagern</li>
  <li>Optimierte Bibliotheken nutzen</li>
  <li>Geeignete Sprache/Plattform wählen</li>
</ul>

### Fazit

Sprachmodelle wie ChatGPT können ein mächtiges Werkzeug für nachhaltiges Programmieren sein – vorausgesetzt, sie werden gezielt eingesetzt. Die Forschung zeigt: **Energieeffizienter Code entsteht nicht automatisch**, sondern erfordert klare Anweisungen, bewusst gewählte Kontexte und die Integration von Green-Coding-Prinzipien in den Entwicklungsprozess. Wer systematisch mit **Custom Instructions**, **Prompting-Strategien** oder eigenen **Styleguides** arbeitet, kann das Potenzial von LLMs für nachhaltige Softwareentwicklung bereits heute nutzen – und dabei sowohl den Ressourcenverbrauch senken als auch die Codequalität steigern. Weitere Grundlagen und Hintergründe zum Zusammenspiel von KI und Nachhaltigkeit finden sich im ersten Teil unserer Artikelserie ([Künstliche Intelligenz - Zwischen Heilsversprechen und Innovationsillusion](https://mehrwert.tech/KI)).
